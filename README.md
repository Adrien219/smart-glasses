# smart-glasses
Ce projet consiste Ã  dÃ©velopper des lunettes intelligentes assistÃ©es par intelligence artificielle, destinÃ©es Ã  aider les personnes aveugles ou malvoyantes Ã  se dÃ©placer de maniÃ¨re plus sÃ»re et autonome.




# ğŸ“‹ DOCUMENTATION TECHNIQUE ULTRA-DÃ‰TAILLÃ‰E - SMART GLASSES

## ğŸ¯ **OBJECTIF GLOBAL DU PROJET**

### **ProblÃ©matique AdressÃ©e**
CrÃ©er un systÃ¨me de lunettes intelligentes **assistant les personnes malvoyantes** en fournissant une perception augmentÃ©e de l'environnement via :
- **Reconnaissance visuelle** en temps rÃ©el des obstacles, objets, textes et visages
- **Interface non-visuelle** par retour vocal et haptique
- **Navigation autonome** avec guidage contextuel
- **Interaction mains-libres** via commandes vocales et contrÃ´les physiques simples

### **Public Cible Principal**
- Personnes malvoyantes et non-voyantes
- Personnes Ã¢gÃ©es avec dÃ©ficience visuelle
- Professionnels en situation de handicap visuel

## ğŸ—ï¸ **ARCHITECTURE SYSTÃˆME COMPLÃˆTE**

### **ğŸ“ Structure DÃ©taillÃ©e du DÃ©pÃ´t GitHub**

```
smart-glasses/
â”œâ”€â”€ ğŸ–¥ï¸  RASPBERY-PI/ (Version de production)
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ camera_processor.py
â”‚   â”œâ”€â”€ arduino_communicator.py
â”‚   â”œâ”€â”€ hardware/
â”‚   â”‚   â”œâ”€â”€ camera_manager.py
â”‚   â”‚   â””â”€â”€ arduino_communication.py
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ object_detector.py
â”‚   â”‚   â”œâ”€â”€ face_recognizer.py
â”‚   â”‚   â”œâ”€â”€ text_recognizer.py
â”‚   â”‚   â”œâ”€â”€ navigation_brain.py
â”‚   â”‚   â”œâ”€â”€ ai_assistant.py
â”‚   â”‚   â””â”€â”€ voice_commands.py
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â””â”€â”€ settings.py
â”‚   â””â”€â”€ web/ (Interface de contrÃ´le)
â”‚
â”œâ”€â”€ ğŸ’» WINDOWS/ (Version de dÃ©veloppement)
â”‚   â””â”€â”€ main.py
â”‚
â”œâ”€â”€ ğŸ”Œ HARDWARE/ (SchÃ©mas Ã©lectroniques)
â”‚   â”œâ”€â”€ arduino/
â”‚   â””â”€â”€ esp32/
â”‚
â””â”€â”€ ğŸ“š DOCS/ (Documentation)
```

### **ğŸ”„ Flux de DonnÃ©es Principal**

```
[Capteurs MatÃ©riels]
        â†“
[MicrocontrÃ´leurs Arduino/ESP32]
        â†“
[Communication SÃ©rie/WiFi]
        â†“
[ContrÃ´leur Principal Raspberry Pi]
        â†“
[Modules de Traitement IA]
        â†“
[Gestionnaire de DÃ©cisions]
        â†“
[Sorties Utilisateur (Vocale/Haptique)]
```

## ğŸ”§ **COMPOSANTS LOGICIELS DÃ‰TAILLÃ‰S**

### **1. ğŸ›ï¸ COUCHE MATÃ‰RIELLE (Hardware)**

#### **`hardware/camera_manager.py`**
```python
FONCTIONNALITÃ‰S :
â”œâ”€â”€ ğŸ“· Gestion multi-sources camÃ©ra
â”‚   â”œâ”€â”€ Camera Raspberry Pi (module CSI)
â”‚   â”œâ”€â”€ Camera USB (logitech, etc.)
â”‚   â””â”€â”€ Fallback automatique si module manquant
â”œâ”€â”€ âš™ï¸ Configuration rÃ©solution dynamique
â”‚   â”œâ”€â”€ 640x480 (dÃ©faut)
â”‚   â”œâ”€â”€ 1280x720 (HD)
â”‚   â””â”€â”€ Adaptation automatique aux performances
â”œâ”€â”€ ğŸ”„ Switch dynamique entre camÃ©ras
â”‚   â”œâ”€â”€ Basculement via commande bouton
â”‚   â”œâ”€â”€ Conservation du contexte
â”‚   â””â”€â”€ RÃ©initialisation propre
â””â”€â”€ ğŸ›¡ï¸ Gestion d'erreurs robuste
    â”œâ”€â”€ Timeouts de connexion
    â”œâ”€â”€ Reconnexion automatique
    â””â”€â”€ Mode dÃ©gradÃ© sans camÃ©ra
```

#### **`hardware/arduino_communication.py`**
```python
ARCHITECTURE :
â”œâ”€â”€ ğŸ”Œ DÃ©tection automatique des ports
â”‚   â”œâ”€â”€ Scan COM1-COM10 (Windows)
â”‚   â”œâ”€â”€ Scan /dev/ttyUSB*, /dev/ttyACM* (Linux)
â”‚   â””â”€â”€ Priorisation des ports actifs
â”œâ”€â”€ ğŸ“¨ Protocole de communication
â”‚   â”œâ”€â”€ Format: "COMMAND:VALUE\n"
â”‚   â”œâ”€â”€ Commands: BUTTON, JOYSTICK, MODE_CHANGE, LIGHT_LEVEL
â”‚   â””â”€â”€ Baud rate: 9600 (stabilitÃ©)
â”œâ”€â”€ ğŸ”„ SystÃ¨me de callbacks
â”‚   â”œâ”€â”€ Enregistrement multiples listeners
â”‚   â”œâ”€â”€ Distribution asynchrone des messages
â”‚   â””â”€â”€ Gestion des prioritÃ©s
â””â”€â”€ âš¡ Envoi de commandes
    â”œâ”€â”€ LED:r,g,b â†’ ContrÃ´le LED RGB
    â”œâ”€â”€ BEEP:freq,duration â†’ Retour haptique
    â””â”€â”€ Validation de rÃ©ception
```

#### **`hardware/esp32_simple_camera.py`** (âœ… NOUVEAU)
```python
COMPOSANTS TECHNIQUES :
â”œâ”€â”€ ğŸŒ Client HTTP Stream
â”‚   â”œâ”€â”€ URL: http://{ip}/stream
â”‚   â”œâ”€â”€ Format: MJPEG over HTTP
â”‚   â””â”€â”€ Timeout: 3 secondes
â”œâ”€â”€ ğŸ§µ Thread de Capture
â”‚   â”œâ”€â”€ Thread sÃ©parÃ© non-bloquant
â”‚   â”œâ”€â”€ Buffer de frame unique
â”‚   â””â”€â”€ Synchronisation verrou minimal
â”œâ”€â”€ ğŸ”§ Gestion Connexion
â”‚   â”œâ”€â”€ Test de vivacitÃ© pÃ©riodique
â”‚   â”œâ”€â”€ Reconnexion automatique
â”‚   â””â”€â”€ Fallback vers mode simulation
â”œâ”€â”€ ğŸ’¡ ContrÃ´le Flash
â”‚   â”œâ”€â”€ Endpoint: /flash
â”‚   â”œâ”€â”€ MÃ©thode: GET
â”‚   â””â”€â”€ Retour: 200 OK / Timeout
â””â”€â”€ ğŸ—œï¸ Optimisations
    â”œâ”€â”€ Skip frames si buffer plein
    â”œâ”€â”€ DÃ©lai configurable (30 FPS)
    â””â”€â”€ LibÃ©ration mÃ©moire garantie
```

### **2. ğŸ§  INTELLIGENCE ARTIFICIELLE (Core)**

#### **`core/object_detector.py`**
```python
MODÃˆLE YOLOv8 - CONFIGURATION :
â”œâ”€â”€ ğŸ¯ ModÃ¨le: yolov8n.pt (nano - optimisÃ© RPi)
â”‚   â”œâ”€â”€ 80 classes COCO
â”‚   â”œâ”€â”€ Input: 640x640
â”‚   â””â”€â”€ OptimisÃ© CPU/GPU faible puissance
â”œâ”€â”€ ğŸ” Pipeline de DÃ©tection
â”‚   â”œâ”€â”€ Preprocessing: Normalisation RGB
â”‚   â”œâ”€â”€ Inference: YOLOv8 via Ultralytics
â”‚   â”œâ”€â”€ Post-processing: NMS + filtrage confiance
â”‚   â””â”€â”€ Formatage: [{class, confidence, bbox}]
â”œâ”€â”€ ğŸ–¼ï¸ Visualisation
â”‚   â”œâ”€â”€ Bounding boxes colorÃ©es
â”‚   â”œâ”€â”€ Labels avec scores
â”‚   â””â”€â”€ Overlay transparent
â””-- âš¡ Performances
    â”œâ”€â”€ CPU: ~100-150ms/frame
    â”œâ”€â”€ GPU: ~20-50ms/frame (si disponible)
    â””-- Optimisation: Half-precision
```

#### **`core/face_recognizer.py`**
```python
RECONNAISSANCE FACIALE - Ã‰TAT :
â”œ-- âš ï¸ ACTUELLEMENT DÃ‰SACTIVÃ‰ (Correctif appliquÃ©)
â”‚   â””-- safe_detect_faces() â†’ [] (retour vide)
â”œ-- ğŸ—ï¸ ARCHITECTURE ORIGINALE
â”‚   â”œ-- BibliothÃ¨que: face_recognition (dlib)
â”‚   â”œ-- Encodages: 128-dimensions
â”‚   â”œ-- Matching: distance euclidienne
â”‚   â””-- Base: known_faces/ (dataset entraÃ®nÃ©)
â”œ-- ğŸ“Š MÃ©triques
â”‚   â”œ-- PrÃ©cision: ~99% LFW
â”‚   â”œ-- Latence: ~200-300ms/face
â”‚   â””-- MÃ©moire: ~100MB/1000 visages
â””-- ğŸ”§ PROBLÃˆME IDENTIFIÃ‰
    â”œ-- Erreur: "tuple indices must be integers or slices, not str"
    â”œ-- Cause: Format de retour face_locations incompatible
    â””-- Solution: Conversion explicite en int
```

#### **`core/text_recognizer.py`**
```python
OCR EASYOCR - IMPLÃ‰MENTATION :
â”œ-- ğŸ—ï¸ Moteur: EasyOCR
â”‚   â”œ-- Langues: ['fr', 'en']
â”‚   â”œ-- Backbone: CRNN + CTC
â”‚   â””-- DÃ©tecteur: CRAFT
â”œ-- ğŸ“ Pipeline Texte
â”‚   â”œ-- DÃ©tection rÃ©gions texte
â”‚   â”œ-- Reconnaissance caractÃ¨res
â”‚   â”œ-- Filtrage confiance (>0.6)
â”‚   â””-- AgrÃ©gation lignes
â”œ-- ğŸ¯ Performances
â”‚   â”œ-- CPU: ~500-1000ms/image
â”‚   â”œ-- PrÃ©cision: ~85-90% texte clair
â”‚   â””-- Support: multi-langues
â””-- âš¡ Optimisations
    â”œ-- Redimensionnement image
    â”œ-- ROI selection
    â””-- Cache modÃ¨les
```

#### **`core/navigation_brain.py`**
```python
LOGIQUE DE NAVIGATION :
â”œ-- ğŸ§­ Analyse Spatiale
â”‚   â”œ-- Position obstacles dans frame
â”‚   â”œ-- Zones: gauche, centre, droite
â”‚   â”œ-- Distance estimÃ©e (taille bbox)
â”‚   â””-- Trajectoire recommandÃ©e
â”œ-- ğŸ—£ï¸ Instructions Vocales
â”‚   â”œ-- "Obstacle Ã  gauche - Serrez Ã  droite"
â”‚   â”œ-- "Passage libre - Avancez droit"
â”‚   â”œ-- "Porte dÃ©tectÃ©e - Centrez-vous"
â”‚   â””-- Urgence: "ArrÃªt - Obstacle proche"
â”œ-- âš ï¸ SystÃ¨me d'Alerte
â”‚   â”œ-- Niveaux: Info, Avertissement, Danger
â”‚   â”œ-- Priorisation alertes
â”‚   â””-- Ã‰viction doublons
â””-- ğŸ“Š Cartographie Mentale
    â”œ-- MÃ©moire obstacles rÃ©cents
    â”œ-- Pattern reconnaissance environnements
    â””-- Adaptation comportementale
```

#### **`core/ai_assistant.py`**
```python
ASSISTANT OPENAI :
â”œ-- ğŸŒ IntÃ©gration API
â”‚   â”œ-- ModÃ¨le: gpt-3.5-turbo (Ã©quilibre coÃ»t/performance)
â”‚   â”œ-- Token limit: 4096
â”‚   â””-- Temperature: 0.7 (crÃ©ativitÃ© contrÃ´lÃ©e)
â”œ-- ğŸ’¬ Contexte Conversationnel
â”‚   â”œ-- Memory: 10 derniers Ã©changes
â”‚   â”œ-- Context: "Vous Ãªtes un assistant pour personne malvoyante"
â”‚   â””-- Personnalisation: ton calme et informatif
â”œ-- ğŸ”„ Workflow Interaction
â”‚   â”œ-- Ã‰coute commande vocale
â”‚   â”œ-- Transcription â†’ OpenAI
â”‚   â”œ-- SynthÃ¨se rÃ©ponse vocale
â”‚   â””-- Log conversation
â””-- âš¡ Limitations
    â”œ-- DÃ©pendance connexion Internet
    â”œ-- Latence: 2-5 secondes/rÃ©ponse
    â””-- CoÃ»t API Ã  monitorer
```

#### **`core/voice_commands.py`**
```python
SYSTÃˆME DE COMMANDES VOCALES :
â”œ-- ğŸ¤ Reconnaissance (Ã€ IMPLÃ‰MENTER)
â”‚   â”œ-- BibliothÃ¨que: SpeechRecognition
â”‚   â”œ-- Moteurs: Google, Sphinx, Vosk
â”‚   â””-- Micro: USB ou intÃ©grÃ© RPi
â”œ-- ğŸ—£ï¸ Commandes SupportÃ©es
â”‚   â”œ-- "Change mode" â†’ cycle modes
â”‚   â”œ-- "Lisez ce texte" â†’ activation OCR
â”‚   â”œ-- "Qui est lÃ  ?" â†’ reconnaissance faciale
â”‚   â”œ-- "OÃ¹ suis-je ?" â†’ description environnement
â”‚   â””-- "Aide" â†’ liste commandes
â”œ-- ğŸ”§ Configuration
â”‚   â”œ-- SensibilitÃ© microphone
â”‚   â”œ-- Mot-clÃ© d'activation
â”‚   â””-- Timeout Ã©coute
â””-- ğŸ›¡ï¸ Robustesse
    â”œ-- Filtrage bruit ambiant
    â”œ-- Correction phrases incomplÃ¨tes
    â””-- Fallback commandes simples
```

### **3. ğŸ”Š SYSTÃˆME VOCAL (VoiceAssistant)**

```python
ARCHITECTURE VOCALE COMPLÃˆTE :
â”œ-- ğŸ™ï¸ SynthÃ¨se Vocale Multi-Plateformes
â”‚   â”œ-- Windows: pyttsx3 (offline)
â”‚   â”‚   â”œ-- Voices: Microsoft Hortense (fr)
â”‚   â”‚   â”œ-- Rate: 160 mots/minute
â”‚   â”‚   â””-- Volume: 90%
â”‚   â”œ-- Raspberry Pi: espeak-ng (offline)
â”‚   â”‚   â”œ-- Langue: franÃ§ais
â”‚   â”‚   â”œ-- Pitch: 50
â”‚   â”‚   â””-- Amplitude: 100
â”‚   â””-- Fallback: print console
â”œ-- ğŸ“¨ SystÃ¨me File d'Attente
â”‚   â”œ-- PriorityQueue: messages urgents prioritaires
â”‚   â”œ-- Cooldown: 3 secondes entre messages
â”‚   â”œ-- Gestion concurrence: Lock threading
â”‚   â””-- Ã‰viction doublons
â”œ-- ğŸ“³ Retour Haptique
â”‚   â”œ-- Buzzer: bips patterns
â”‚   â”œ-- DurÃ©e: 100-500ms
â”‚   â”œ-- FrÃ©quence: 1000Hz
â”‚   â””-- Synchronisation vocale
â””-- ğŸšï¸ ContrÃ´le Audio
    â”œ-- Interruption messages non-urgents
    â”œ-- Volume adaptatif environnement
    â””-- Test santÃ© vocal au dÃ©marrage
```

### **4. âš™ï¸ CONFIGURATION (Settings)**

#### **`config/settings.py`**
```python
CONFIGURATION GLOBALE DÃ‰TAILLÃ‰E :
â”œ-- ğŸ“· ParamÃ¨tres CamÃ©ra
â”‚   â”œ-- CAMERA_ID: 0 (index USB)
â”‚   â”œ-- CAMERA_RESOLUTION: (640, 480)
â”‚   â”œ-- CAMERA_FPS: 30
â”‚   â””-- CAMERA_ROTATION: 0
â”œ-- ğŸ§  IA et ModÃ¨les
â”‚   â”œ-- YOLO_MODEL_PATH: 'yolov8n.pt'
â”‚   â”œ-- YOLO_CONFIDENCE: 0.5
â”‚   â”œ-- FACE_RECOGNITION_TOLERANCE: 0.6
â”‚   â””-- OCR_LANGUAGES: ['fr', 'en']
â”œ-- ğŸ”Œ Communication
â”‚   â”œ-- ARDUINO_BAUDRATE: 9600
â”‚   â”œ-- ARDUINO_TIMEOUT: 1
â”‚   â”œ-- ESP32_CAM_URL: 'http://10.231.158.139/stream'
â”‚   â””-- ESP32_STATUS_URL: 'http://10.231.158.139/status'
â”œ-- ğŸ® ContrÃ´les
â”‚   â”œ-- JOYSTICK_DEADZONE: 100
â”‚   â”œ-- BUTTON_COOLDOWN: 1.0
â”‚   â””-- MODE_CHANGE_DELAY: 0.5
â”œ-- ğŸ”Š Audio
â”‚   â”œ-- VOICE_RATE: 160
â”‚   â”œ-- VOICE_VOLUME: 0.9
â”‚   â”œ-- BEEP_DURATION: 0.1
â”‚   â””-- SPEECH_COOLDOWN: 3.0
â””-- ğŸ–¥ï¸ Interface
    â”œ-- HEADLESS_MODE: False
    â”œ-- SHOW_DETECTIONS: True
    â””-- DISPLAY_FPS: True
```

## ğŸ”Œ **ARCHITECTURE MATÃ‰RIELLE DÃ‰TAILLÃ‰E**

### **ğŸ“Š SpÃ©cifications Techniques MatÃ©rielles**

#### **Raspberry Pi 4 (Cerveau Central)**
```
SPECIFICATIONS :
â”œ-- Processeur: Broadcom BCM2711 Quad core Cortex-A72 @ 1.5GHz
â”œ-- MÃ©moire: 4GB LPDDR4
â”œ-- Stockage: MicroSD 32GB+ Classe 10
â”œ-- ConnectivitÃ©:
â”‚   â”œ-- WiFi 5 (802.11ac)
â”‚   â”œ-- Bluetooth 5.0
â”‚   â”œ-- 2x USB 3.0, 2x USB 2.0
â”‚   â””-- GPIO 40-pins
â”œ-- Alimentation: 5V/3A USB-C
â””-- Refroidissement: Ventilactif + dissipateur

INTERFACES UTILISÃ‰ES :
â”œ-- CSI: Camera Module V2
â”œ-- USB1: Arduino Nano
â”œ-- USB2: Camera USB (backup)
â”œ-- GPIO: Ã‰ventuels capteurs additionnels
â””-- WiFi: Connection ESP32-CAM
```

#### **Arduino Nano (ContrÃ´leur PÃ©riphÃ©rique)**
```
CARACTÃ‰RISTIQUES :
â”œ-- MicrocontrÃ´leur: ATmega328P
â”œ-- Clock: 16MHz
â”œ-- MÃ©moire: 32KB Flash, 2KB SRAM
â”œ-- EntrÃ©es/Sorties:
â”‚   â”œ-- 14 Digital I/O (dont 6 PWM)
â”‚   â”œ-- 8 Analog Inputs
â”‚   â””-- Communication: UART, I2C, SPI
â””-- Alimentation: 5V via USB

BROCHEAGE DÃ‰TAILLÃ‰ :
â”œ-- ANALOGIQUES :
â”‚   â”œ-- A0: Joystick X-axis
â”‚   â”œ-- A1: Joystick Y-axis  
â”‚   â”œ-- A2: Capteur lumiÃ¨re
â”‚   â””-- A3-A7: RÃ©servÃ©s
â”œ-- DIGITALES :
â”‚   â”œ-- D2: Bouton 1 (Mode Navigation)
â”‚   â”œ-- D3: Bouton 2 (Mode Objets)
â”‚   â”œ-- D4: Bouton 3 (Mode Visages)
â”‚   â”œ-- D5: Bouton 4 (Mode Texte)
â”‚   â”œ-- D6: Bouton 5 (Mode IA)
â”‚   â”œ-- D9: Buzzer (PWM)
â”‚   â”œ-- D10: LED Rouge (PWM)
â”‚   â”œ-- D11: LED Verte (PWM)
â”‚   â””-- D12: LED Bleue (PWM)
â””-- COMMUNICATION :
    â”œ-- D0(RX)/D1(TX): Serial USB
    â””-- D13: LED intÃ©grÃ©e (debug)
```

#### **ESP32-CAM (Module Vision Secondaire)**
```
SPÃ‰CIFICATIONS :
â”œ-- Processeur: ESP32-S Dual-Core 240MHz
â”œ-- MÃ©moire: 520KB SRAM, 4MB PSRAM
â”œ-- Camera: OV2640 2MP
â”œ-- ConnectivitÃ©: WiFi 802.11 b/g/n
â”œ-- Flash LED: GPIO4
â””-- Alimentation: 5V externe (critique)

CONFIGURATION RÃ‰SEAU :
â”œ-- Mode: Station (se connecte Ã  WiFi existant)
â”œ-- IP: 10.231.158.139 (statique via DHCP reservation)
â”œ-- Port: 80 (HTTP)
â””-- Endpoints:
    â”œ-- /stream â†’ Flux MJPEG
    â”œ-- /status â†’ Health check
    â””-- /flash â†’ ContrÃ´le LED
```

### **ğŸ”‹ ConsidÃ©rations Alimentation**

```
BESOINS Ã‰NERGÃ‰TIQUES :
â”œ-- Raspberry Pi 4: 3A @ 5V = 15W
â”œ-- Arduino Nano: 0.5A @ 5V = 2.5W  
â”œ-- ESP32-CAM: 0.5A @ 5V = 2.5W (pic dÃ©marrage)
â”œ-- Camera RPi: 0.25A @ 5V = 1.25W
â””-- TOTAL: ~4.25A @ 5V = 21.25W

SOLUTION RECOMMANDÃ‰E :
â”œ-- Batterie: Powerbank 20000mAh @ 5V/3A
â”œ-- Autonomie estimÃ©e: 3-4 heures
â””-- Gestion Ã©nergie: Shutdown propre via software
```

## ğŸ® **MODES DE FONCTIONNEMENT DÃ‰TAILLÃ‰S**

### **Mode 0: ğŸ§­ NAVIGATION**
```python
OBJECTIF: Guidance sÃ©curitaire dans l'environnement

FONCTIONNEMENT :
â”œ-- ğŸ” DÃ©tection en Temps RÃ©el
â”‚   â”œ-- Objets: personne, chaise, table, porte, escalier
â”‚   â”œ-- Obstacles: mur, meuble, vÃ©hicule
â”‚   â””-- Structures: couloir, porte, rampe
â”œ-- ğŸ—ºï¸ Analyse Spatiale
â”‚   â”œ-- Cartographie obstacles gauche/centre/droite
â”‚   â”œ-- Estimation distances relatives
â”‚   â”œ-- Couloirs de circulation
â”‚   â””-- Points d'intÃ©rÃªt (portes, escaliers)
â”œ-- ğŸ—£ï¸ Instructions Vocales
â”‚   â”œ-- "Obstacle Ã  2m - Serrez Ã  droite"
â”‚   â”œ-- "Couloir libre - Avancez droit"  
â”‚   â”œ-- "Porte dÃ©tectÃ©e Ã  gauche - Direction 10h"
â”‚   â””-- "Attention: escalier devant - ArrÃªtez"
â””-- âš ï¸ SystÃ¨me d'Alerte
    â”œ-- Niveau 1: Information (obstacles lointains)
    â”œ-- Niveau 2: Avertissement (obstacles proches)
    â”œ-- Niveau 3: Danger (collision imminente)
    â””-- Priorisation: danger > proximitÃ© > information
```

### **Mode 1: ğŸ“¦ RECONNAISSANCE OBJETS**
```python
OBJECTIF: Identifier et annoncer les objets environnants

CLASSES DÃ‰TECTÃ‰ES (sÃ©lection):
â”œ-- ğŸ  Domestique: 
â”‚   â”œ-- chaise, table, lit, canapÃ©, tÃ©lÃ©vision
â”‚   â”œ-- frigo, four, micro-ondes, Ã©vier
â”‚   â””-- horloge, vase, livre, tÃ©lÃ©phone
â”œ-- ğŸ½ï¸ Nourriture:
â”‚   â”œ-- pomme, banane, orange, sandwich
â”‚   â”œ-- bouteille, verre, tasse, assiette
â”‚   â””-- couteau, fourchette, cuillÃ¨re
â”œ-- ğŸšª Mobilier:
â”‚   â”œ-- porte, fenÃªtre, toilette, lavabo
â”‚   â”œ-- escalier, interrupteur, miroir
â”‚   â””-- placard, Ã©tagÃ¨re, commode
â”œ-- ğŸ‘¤ Personnes & Animaux:
â”‚   â”œ-- personne, enfant, chien, chat
â”‚   â””-- oiseau, cheval, mouton
â””-- ğŸš— ExtÃ©rieur:
    â”œ-- voiture, moto, vÃ©lo, bus, train
    â”œ-- panneau, feu tricolore, banc
    â””-- arbre, fleur, herbe

ANNONCES VOCALES:
â”œ-- Format: "Objets dÃ©tectÃ©s: [liste]"
â”œ-- Filtrage: objets avec confidence > 50%
â”œ-- Limite: 5 objets maximum par annonce
â””-- Cooldown: 3 secondes entre annonces
```

### **Mode 2: ğŸ‘¤ RECONNAISSANCE FACIALE** 
```python
âš ï¸ ACTUELLEMENT DÃ‰SACTIVÃ‰ - Correctif appliquÃ©

ARCHITECTURE ORIGINALE:
â”œ-- ğŸ—‚ï¸ Base de Visages Connus
â”‚   â”œ-- Dossier: known_faces/
â”‚   â”œ-- Format: images JPG/PNG
â”‚   â”œ-- Nommage: "prenom_nom.jpg"
â”‚   â””-- EntraÃ®nement: automatique au dÃ©marrage
â”œ-- ğŸ” Pipeline Reconnaissance
â”‚   â”œ-- DÃ©tection visages: HOG + SVM
â”‚   â”œ-- Encodage: ResNet 128D
â”‚   â”œ-- Comparaison: distance euclidienne
â”‚   â””-- Seuil: tolerance=0.6
â”œ-- ğŸ¯ Performance Attendue
â”‚   â”œ-- PrÃ©cision: 99.38% LFW
â”‚   â”œ-- Latence: 200ms/face
â”‚   â””-- Multi-faces: jusqu'Ã  10 simultanÃ©es
â””-- ğŸ—£ï¸ Annonces
    â”œ-- Connu: "Adrien est devant vous"
    â”œ-- Inconnu: "Personne non reconnue"
    â””-- Multiple: "3 personnes dÃ©tectÃ©es"

PROBLÃˆME ACTUEL:
â”œ-- Erreur: "tuple indices must be integers or slices, not str"
â”œ-- Localisation: face_recognition.face_locations()
â”œ-- Cause: Format de retour incompatible
â””-- Solution: Wrapper de conversion types
```

### **Mode 3: ğŸ“ LECTURE TEXTE**
```python
OBJECTIF: Lire et annoncer le texte dans l'environnement

CAS D'USAGE:
â”œ-- ğŸ“– Lecture documents: livres, magazines, journaux
â”œ-- ğŸ·ï¸ Ã‰tiquettes: produits, mÃ©dicaments, nourriture
â”œ-- ğŸš SignalÃ©tique: panneaux, rues, portes
â”œ-- ğŸ–¥ï¸ Ã‰crans: tÃ©lÃ©phone, ordinateur, tÃ©lÃ©vision
â””-- ğŸ“„ Formulaires: administrations, banques

CONFIGURATION OCR:
â”œ-- Moteur: EasyOCR
â”œ-- Langues: franÃ§ais, anglais
â”œ-- DÃ©tecteur: CRAFT (Character Region Awareness)
â”œ-- Reconnaissance: CRNN (Convolutional Recurrent NN)
â””-- Post-processing: correction orthographique

SEUILS ET FILTRES:
â”œ-- Confidence minimale: 0.6 (60%)
â”œ-- Longueur minimale: 2 caractÃ¨res
â”œ-- Filtrage bruit: symboles isolÃ©s
â””-- AgrÃ©gation: lignes â†’ paragraphes

ANNONCES:
â”œ-- Format: "Texte dÃ©tectÃ©: [contenu]"
â”œ-- Limite: 200 caractÃ¨res par annonce
â”œ-- PrioritÃ©: plus haute confidence
â””-- FrÃ©quence: immÃ©diate si nouveau texte
```

### **Mode 4: ğŸ¤– ASSISTANT IA**
```python
OBJECTIF: Assistant conversationnel contextuel

CAPACITÃ‰S:
â”œ-- ğŸ’¬ Questions gÃ©nÃ©rales: connaissances, calculs
â”œ-- ğŸ  Contexte domestique: recettes, conseils
â”œ-- ğŸš¶ Orientation: directions, transports
â”œ-- ğŸ“… Organisation: agenda, rappels
â””-- ğŸ†˜ Urgence: contacts, procÃ©dures

INTÃ‰GRATION OPENAI:
â”œ-- ModÃ¨le: gpt-3.5-turbo
â”œ-- Contexte systÃ¨me: "Assistant pour personne malvoyante"
â”œ-- Memory: 10 derniers messages
â”œ-- Temperature: 0.7 (crÃ©ativitÃ© Ã©quilibrÃ©e)
â””-- Max tokens: 500 (rÃ©ponses concises)

WORKFLOW:
â”œ-- 1. Ã‰coute commande vocale (Ã€ IMPLÃ‰MENTER)
â”œ-- 2. Transcription speech-to-text
â”œ-- 3. Envoi Ã  OpenAI API
â”œ-- 4. RÃ©ception et parsing rÃ©ponse
â””-- 5. SynthÃ¨se vocale rÃ©ponse

LIMITATIONS:
â”œ-- DÃ©pendance Internet
â”œ-- Latence: 2-5 secondes
â”œ-- CoÃ»t: ~$0.002/request
â””-- ConfidentialitÃ©: donnÃ©es externes
```

## âš¡ **SYSTÃˆME DE COMMUNICATION DÃ‰TAILLÃ‰**

### **Protocole Arduino â†” Raspberry Pi**

```
FORMAT DES MESSAGES:
â”Œ-- STRUCTURE: "COMMAND:VALUE\n"
â”œ-- ENCODAGE: ASCII
â”œ-- BAUD RATE: 9600
â””-- PARITÃ‰: 8N1

COMMANDES REÃ‡UES (Arduino â†’ RPi):
â”œ-- "BUTTON:X"          // Bouton X pressÃ© (1-5)
â”œ-- "JOYSTICK:X,Y"      // Position joystick (0-1023)
â”œ-- "MODE_CHANGE:X"     // Changement mode rotatif (0-4)  
â”œ-- "LIGHT_LEVEL:X"     // Niveau luminositÃ© (0-1023)
â””-- "ARDUINO_READY"     // Initialisation terminÃ©e

COMMANDES ENVOYÃ‰ES (RPi â†’ Arduino):
â”œ-- "LED:R,G,B"         // ContrÃ´le LED RGB (0-255)
â”œ-- "BEEP:FREQ,DURATION" // Buzzer (Hz, ms)
â””-- "VIBRATE:PATTERN"   // Moteur vibration (Ã€ IMPLÃ‰MENTER)
```

### **Communication ESP32-CAM**

```
ENDPOINTS HTTP ESP32:
â”œ-- GET /stream
â”‚   â””-- Retour: Flux MJPEG (multipart/x-mixed-replace)
â”œ-- GET /status  
â”‚   â””-- Retour: "OK" (texte simple)
â”œ-- GET /flash
â”‚   â””-- Action: Bascule LED flash
â””-- GET /capture
    â””-- Retour: Image JPEG unique

CONFIGURATION RÃ‰SEAU:
â”œ-- Mode: Station WiFi
â”œ-- SSID: [configurÃ© dans code]
â”œ-- Password: [configurÃ© dans code]
â”œ-- IP: Dynamique (DHCP) avec rÃ©servation
â””-- Port: 80

GESTION ERREURS:
â”œ-- Timeout connexion: 3 secondes
â”œ-- Reconnexion automatique: toutes les 5 secondes
â”œ-- Fallback: mode simulation
â””-- Logs: dÃ©taillÃ©s avec codes erreur HTTP
```

## ğŸ› ï¸ **Ã‰TAT D'AVANCEMENT DÃ‰TAILLÃ‰**

### **âœ… FONCTIONNALITÃ‰S COMPLÃˆTEMENT OPÃ‰RATIONNELLES**

#### **Noyau SystÃ¨me**
- [x] **Initialisation automatique** de tous les composants
- [x] **Gestion d'erreurs robuste** avec fallbacks
- [x] **Communication Arduino** bidirectionnelle stable
- [x] **SystÃ¨me de logging** dÃ©taillÃ© avec mÃ©triques
- [x] **ArrÃªt propre** avec libÃ©ration ressources

#### **Vision par Ordinateur**
- [x] **DÃ©tection d'objets YOLOv8** temps rÃ©el
- [x] **OCR texte EasyOCR** avec filtrage confidence
- [x] **Multi-sources camÃ©ra** (RPi + USB + ESP32)
- [x] **Visualisation temps rÃ©el** avec overlay

#### **Interface Utilisateur**
- [x] **Changement de modes** via boutons physiques
- [x] **Retour vocal** avec file d'attente prioritaire
- [x] **Retour haptique** (buzzer + LED)
- [x] **ContrÃ´le joystick** avec zones mortes
- [x] **Affichage temps rÃ©el** avec informations systÃ¨me

#### **IntÃ©gration MatÃ©rielle**
- [x] **Support Raspberry Pi** optimisÃ©
- [x] **Support Windows** (dÃ©veloppement)
- [x] **Communication sÃ©rie Arduino** stable
- [x] **Stream ESP32-CAM** avec reconnexion
- [x] **Gestion alimentation** et ressources

### **ğŸ”„ FONCTIONNALITÃ‰S EN DÃ‰VELOPPEMENT**

#### **AmÃ©liorations StabilitÃ©**
- [ ] **Reconnaissance faciale** (correctif permanent)
- [ ] **Gestion mÃ©moire** optimisÃ©e long terme
- [ ] **Watchdog systÃ¨me** redÃ©marrage auto
- [ ] **Sauvegarde Ã©tat** entre redÃ©marrages

#### **Nouvelles FonctionnalitÃ©s**
- [ ] **Commandes vocales** (speech-to-text)
- [ ] **Interface web** contrÃ´le distant
- [ ] **Cartographie environnement** 
- [ ] **Mode urgence** contacts + localisation
- [ ] **SystÃ¨me de plugins** extensible

### **ğŸš§ DÃ‰FIS TECHNIQUES EN COURS**

#### **Performance**
```
PROBLÃˆME: Latence OCR sur CPU
â”œ-- Actuel: 500-1000ms/image
â”œ-- Cible: <200ms/image
â”œ-- Solutions:
â”‚   â”œ-- Optimisation modÃ¨le EasyOCR
â”‚   â”œ-- DÃ©tection ROI prÃ©alable
â”‚   â””-- Hardware accÃ©lÃ©ration
â””-- PrioritÃ©: Moyenne

PROBLÃˆME: Consommation mÃ©moire YOLO
â”œ-- Actuel: ~500MB
â”œ-- Cible: <200MB  
â”œ-- Solutions:
â”‚   â”œ-- ModÃ¨le yolov8s (small)
â”‚   â”œ-- Quantization INT8
â”‚   â””-- Cleanup mÃ©moire pÃ©riodique
â””-- PrioritÃ©: Basse
```

#### **Robustesse**
```
PROBLÃˆME: ESP32 dÃ©connexions frÃ©quentes
â”œ-- Cause: Alimentation instable
â”œ-- Impact: Perte flux vidÃ©o secondaire
â”œ-- Solutions:
â”‚   â”œ-- Alimentation externe dÃ©diÃ©e
â”‚   â”œ-- Timeout adaptatif
â”‚   â””-- Cache derniÃ¨res frames
â””-- PrioritÃ©: Ã‰levÃ©e

PROBLÃˆME: Reconnaissance faciale plantage
â”œ-- Erreur: "tuple indices must be integers or slices, not str"
â”œ-- Cause: IncompatibilitÃ© bibliothÃ¨que
â”œ-- Solution: Wrapper de conversion
â””-- PrioritÃ©: Ã‰levÃ©e
```

## ğŸ”® **ROADMAP FUTURE DÃ‰TAILLÃ‰E**

### **Phase 1: Stabilisation (1-2 mois)**
```
OBJECTIF: SystÃ¨me production-ready
â”œ-- âœ… [Fait] Communication matÃ©rielle stable
â”œ-- ğŸ”„ [En Cours] Correctif reconnaissance faciale
â”œ-- ğŸ“ [PlanifiÃ©] Tests intensifs utilisateurs
â”œ-- ğŸ› [PlanifiÃ©] Correction bugs critiques
â””-- ğŸ“Š [PlanifiÃ©] MÃ©triques performance

LIVRABLES:
â”œ-- Version 1.0 stable
â”œ-- Documentation utilisateur
â””-- Scripts installation automatisÃ©e
```

### **Phase 2: FonctionnalitÃ©s AvancÃ©es (3-6 mois)**
```
OBJECTIF: ExpÃ©rience utilisateur enrichie
â”œ-- ğŸ—£ï¸ Interface vocale complÃ¨te (STT + TTS)
â”œ-- ğŸŒ Interface web contrÃ´le distant
â”œ-- ğŸ—ºï¸ Cartographie et navigation avancÃ©e
â”œ-- ğŸ“± Application mobile companion
â””-- ğŸ”Œ API externe pour extensions

LIVRABLES:
â”œ-- Version 2.0 avec interface vocale
â”œ-- Application mobile
â””-- Documentation dÃ©veloppeur
```

### **Phase 3: Optimisation (6-12 mois)**
```
OBJECTIF: Performance et accessibilitÃ©
â”œ-- âš¡ Optimisation temps rÃ©el (latence <100ms)
â”œ-- ğŸ”‹ Gestion Ã©nergie (autonomie 8h+)
â”œ-- ğŸŒ Multi-langues (ES, DE, IT, etc.)
â”œ-- â™¿ AccessibilitÃ© avancÃ©e
â””-- ğŸ“¦ Packaging produit commercial

LIVRABLES:
â”œ-- Version 3.0 optimisÃ©e
â”œ-- Kits matÃ©riels prÃªts Ã  l'emploi
â””-- Certification accessibilitÃ©
```

## ğŸ’¾ **INSTRUCTIONS POUR REPRISE DÃ‰VELOPPEMENT**

### **Environnement de DÃ©veloppement**
```bash
# 1. Cloner le dÃ©pÃ´t
git clone https://github.com/Adrien219/smart-glasses.git
cd smart-glasses

# 2. Environnement virtuel
python -m venv smartglasses-env
source smartglasses-env/bin/activate  # Linux/Mac
# OU
smartglasses-env\Scripts\activate    # Windows

# 3. DÃ©pendances
pip install -r requirements.txt

# 4. Configuration
cp config/settings.example.py config/settings.py
# Ã‰diter settings.py avec vos paramÃ¨tres

# 5. Test
cd raspberry-pi
python main.py
```

### **Structure pour Nouveau DÃ©veloppeur**
```
POINTS D'ENTRÃ‰E PRINCIPAUX:
â”œ-- ğŸš€ main.py â†’ ContrÃ´leur principal
â”œ-- âš™ï¸ config/settings.py â†’ Configuration
â”œ-- ğŸ”Œ hardware/ â†’ Communication matÃ©rielle
â”œ-- ğŸ§  core/ â†’ Intelligence artificielle  
â””-- ğŸ“š docs/ â†’ Documentation

POINTS D'ATTENTION:
â”œ-- Gestion des threads: toujours utiliser daemon=True
â”œ-- Communication sÃ©rie: fermer proprement dans finally
â”œ-- MÃ©moire: libÃ©rer explicitement les modÃ¨les IA lourds
â””-- Logs: utiliser le systÃ¨me de logging intÃ©grÃ©
```

### **Tests et DÃ©bogage**
```python
# Test individuel modules
python -c "from hardware.arduino_communication import ArduinoCommunication; a = ArduinoCommunication(); print(a.connect())"

# Test camÃ©ra seule  
python -c "import cv2; cap = cv2.VideoCapture(0); print('Camera OK' if cap.isOpened() else 'Camera FAIL'); cap.release()"

# Mode debug
export SMARTGLASSES_DEBUG=1
python main.py
```

Cette documentation technique ultra-dÃ©taillÃ©e permet Ã  n'importe quel dÃ©veloppeur de reprendre le projet en ayant une comprÃ©hension complÃ¨te de l'architecture, des composants, de leur Ã©tat actuel et des prochaines Ã©tapes. Le systÃ¨me est fonctionnel mais nÃ©cessite des amÃ©liorations de stabilitÃ© et de nouvelles fonctionnalitÃ©s pour atteindre sa pleine potentiel. ğŸš€