import speech_recognition as sr
import threading
import time
import queue

class VoiceCommands:
    def __init__(self, smart_glasses_system):
        self.system = smart_glasses_system
        self.recognizer = sr.Recognizer()
        self.microphone = sr.Microphone()
        self.command_queue = queue.Queue()
        self.is_listening = False
        self.listening_thread = None
        
        # Calibration du microphone pour le bruit ambiant
        print("üé§ Calibration du microphone...")
        with self.microphone as source:
            self.recognizer.adjust_for_ambient_noise(source, duration=2)
        print("‚úÖ Microphone calibr√©!")
        
        # Dictionnaire des commandes vocales
        self.voice_commands = {
            # Changement de modes
            "mode navigation": "navigation",
            "mode objets": "object", 
            "mode objet": "object",
            "mode d√©tection d'objets": "object",
            "mode visages": "face",
            "mode reconnaissance faciale": "face",
            "mode texte": "text",
            "mode lecture": "text",
            "mode assistant": "ai",
            "mode ia": "ai",
            
            # Commandes de navigation
            "o√π suis-je": "where_am_i",
            "que vois-tu": "what_do_you_see",
            "qui est l√†": "who_is_there",
            "d√©cris la sc√®ne": "describe_scene",
            "obstacles": "detect_obstacles",
            "guide moi": "guide_me",
            
            # Commandes syst√®me
            "arr√™te": "stop",
            "d√©marre": "start",
            "aide": "help",
            "statut": "status",
            
            # Commandes de lecture
            "lis le texte": "read_text",
            "texte devant": "read_text",
            
            # Commandes d'assistant
            "que peux-tu faire": "capabilities",
            "commandes disponibles": "available_commands"
        }

    def start_listening(self):
        """D√©marre l'√©coute des commandes vocales"""
        if self.is_listening:
            return
            
        self.is_listening = True
        self.listening_thread = threading.Thread(target=self._listen_loop, daemon=True)
        self.listening_thread.start()
        print("üé§ Reconnaissance vocale activ√©e - Dites 'aide' pour la liste des commandes")

    def stop_listening(self):
        """Arr√™te l'√©coute des commandes vocales"""
        self.is_listening = False
        if self.listening_thread:
            self.listening_thread.join(timeout=2.0)
        print("üîá Reconnaissance vocale d√©sactiv√©e")

    def _listen_loop(self):
        """Boucle d'√©coute principale"""
        while self.is_listening:
            try:
                # √âcoute avec timeout pour pouvoir v√©rifier is_listening
                with self.microphone as source:
                    audio = self.recognizer.listen(source, timeout=1, phrase_time_limit=5)
                
                # Transcription
                try:
                    command = self.recognizer.recognize_google(audio, language='fr-FR')
                    command = command.lower()
                    print(f"üé§ Commande vocale d√©tect√©e: '{command}'")
                    
                    # Traitement de la commande
                    self._process_voice_command(command)
                    
                except sr.UnknownValueError:
                    # Pas de parole d√©tect√©e ou incompr√©hensible
                    pass
                except sr.RequestError as e:
                    print(f"‚ùå Erreur service reconnaissance vocale: {e}")
                    
            except sr.WaitTimeoutError:
                # Timeout normal, on continue la boucle
                continue
            except Exception as e:
                print(f"‚ùå Erreur √©coute vocale: {e}")
                time.sleep(1)

    def _process_voice_command(self, command_text):
        """Traite la commande vocale et d√©clenche l'action correspondante"""
        # Recherche de correspondance dans les commandes
        for voice_cmd, action in self.voice_commands.items():
            if voice_cmd in command_text:
                self._execute_command(action, command_text)
                return
        
        # Si aucune commande reconnue
        self.system.voice_assistant.speak("Commande non reconnue. Dites 'aide' pour la liste des commandes.")

    def _execute_command(self, action, original_command):
        """Ex√©cute l'action correspondant √† la commande"""
        try:
            if action in ["navigation", "object", "face", "text", "ai"]:
                # Changement de mode
                self.system.set_mode(action)
                self.system.voice_assistant.speak(f"Mode {action} activ√©")
                
            elif action == "what_do_you_see":
                self._handle_what_do_you_see()
                
            elif action == "who_is_there":
                self._handle_who_is_there()
                
            elif action == "read_text":
                self._handle_read_text()
                
            elif action == "describe_scene":
                self._handle_describe_scene()
                
            elif action == "guide_me":
                self._handle_guide_me()
                
            elif action == "help":
                self._handle_help()
                
            elif action == "capabilities":
                self._handle_capabilities()
                
            elif action == "available_commands":
                self._handle_available_commands()
                
            else:
                self.system.voice_assistant.speak(f"Commande {action} en cours de d√©veloppement")
                
        except Exception as e:
            print(f"‚ùå Erreur ex√©cution commande {action}: {e}")
            self.system.voice_assistant.speak("Erreur lors de l'ex√©cution de la commande")

    def _handle_what_do_you_see(self):
        """Traite la commande 'que vois-tu'"""
        # Capture une frame et d√©tecte les objets
        frame = self.system.camera.get_frame()
        if frame is not None:
            detections = self.system.object_detector.detect_objects(frame)
            if detections:
                objects = list(set([det['class'] for det in detections]))
                objects_text = ", ".join(objects[:5])  # Limiter √† 5 objets
                response = f"Je vois: {objects_text}"
            else:
                response = "Je ne vois aucun objet pour le moment"
        else:
            response = "Probl√®me avec la cam√©ra"
        
        self.system.voice_assistant.speak(response)

    def _handle_who_is_there(self):
        """Traite la commande 'qui est l√†'"""
        frame = self.system.camera.get_frame()
        if frame is not None:
            faces = self.system.face_recognizer.detect_faces(frame)
            if faces:
                names = [face['name'] for face in faces if face['name'] != "Inconnu"]
                if names:
                    names_text = ", ".join(names)
                    response = f"Je vois: {names_text}"
                else:
                    response = "Je vois des personnes mais je ne les reconnais pas"
            else:
                response = "Je ne vois personne"
        else:
            response = "Probl√®me avec la cam√©ra"
        
        self.system.voice_assistant.speak(response)

    def _handle_read_text(self):
        """Traite la commande 'lis le texte'"""
        frame = self.system.camera.get_frame()
        if frame is not None:
            text_info = self.system.text_recognizer.extract_text(frame)
            if text_info:
                # Prendre le texte avec la plus haute confiance
                best_text = max(text_info, key=lambda x: x['confidence'])
                response = f"Je lis: {best_text['text']}"
            else:
                response = "Je ne vois pas de texte"
        else:
            response = "Probl√®me avec la cam√©ra"
        
        self.system.voice_assistant.speak(response)

    def _handle_describe_scene(self):
        """Traite la commande 'd√©cris la sc√®ne'"""
        frame = self.system.camera.get_frame()
        if frame is None:
            self.system.voice_assistant.speak("Probl√®me avec la cam√©ra")
            return
            
        # D√©tection compl√®te
        objects = self.system.object_detector.detect_objects(frame)
        faces = self.system.face_recognizer.detect_faces(frame)
        text_info = self.system.text_recognizer.extract_text(frame)
        
        description_parts = []
        
        if objects:
            obj_names = list(set([det['class'] for det in objects[:3]]))
            description_parts.append(f"objets: {', '.join(obj_names)}")
            
        if faces:
            known_faces = [face['name'] for face in faces if face['name'] != "Inconnu"]
            if known_faces:
                description_parts.append(f"personnes: {', '.join(known_faces)}")
            else:
                description_parts.append("personnes non reconnues")
                
        if text_info:
            description_parts.append("texte d√©tect√©")
            
        if description_parts:
            response = "Sc√®ne: " + ", ".join(description_parts)
        else:
            response = "Rien de particulier √† d√©crire"
            
        self.system.voice_assistant.speak(response)

    def _handle_guide_me(self):
        """Traite la commande 'guide moi'"""
        self.system.voice_assistant.speak("Mode guidage activ√©. Je vais vous aider √† naviguer.")
        # Ici vous pourriez activer un mode de guidage sp√©cial
        self.system.set_mode("navigation")

    def _handle_help(self):
        """Affiche l'aide des commandes vocales"""
        help_text = """
Commandes disponibles:
- Modes: 'mode navigation', 'mode objets', 'mode visages', 'mode texte', 'mode assistant'
- Informations: 'que vois-tu', 'qui est l√†', 'd√©cris la sc√®ne'
- Lecture: 'lis le texte'
- Navigation: 'guide moi', 'obstacles'
- Aide: 'aide', 'commandes disponibles'
        """
        print(help_text)
        self.system.voice_assistant.speak("Je vous ai affich√© la liste des commandes dans la console. Dites par exemple 'mode objets' pour changer de mode.")

    def _handle_capabilities(self):
        """D√©crit les capacit√©s du syst√®me"""
        capabilities = """
Je peux:
- D√©tecter et reconna√Ætre les objets autour de vous
- Reconna√Ætre les visages des personnes que vous connaissez  
- Lire le texte devant vous
- Vous guider et d√©tecter les obstacles
- R√©pondre √† vos questions
        """
        print(capabilities)
        self.system.voice_assistant.speak("Je peux d√©tecter objets, reconna√Ætre visages, lire texte, et vous guider. Dites 'aide' pour les commandes.")

    def _handle_available_commands(self):
        """Liste les commandes disponibles"""
        self._handle_help()